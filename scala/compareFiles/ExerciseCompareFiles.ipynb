{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8aa024-0f8c-48bd-9f63-bce21d2a79a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.ClassNotFoundException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "java.lang.ClassNotFoundException:",
      "Failed to find data source: com.databricks.spark.xml. Please find packages at",
      "http://spark.apache.org/third-party-projects.html",
      "",
      "  at org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:443)",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:670)",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:720)",
      "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)",
      "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:188)",
      "  ... 38 elided",
      "Caused by: java.lang.ClassNotFoundException: com.databricks.spark.xml.DefaultSource",
      "  at scala.reflect.internal.util.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:72)",
      "  at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)",
      "  at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:656)",
      "  at scala.util.Try$.apply(Try.scala:213)",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:656)",
      "  at scala.util.Failure.orElse(Try.scala:224)",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:656)",
      "  ... 41 more",
      ""
     ]
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "//Create DataFrame of Csv\n",
    "val dfCsv = spark.read.option(\"sep\",\";\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"../../resources/compareFiles/people.csv\")\n",
    "          .sort($\"id\")\n",
    "//Create Dataframe of xml\n",
    "val dfXml = spark.read.format(\"com.databricks.spark.xml\").option(\"rowTag\",\"\").option(\"order\",\"false\").load(\"../../resources/compareFiles/people.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af588d67-148d-4c1b-b02e-ed1533cdb91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
